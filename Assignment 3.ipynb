{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training Accuracy  Validation Accuracy\n",
      "DT          47.279761            73.447331\n",
      "RF          29.577455            45.059351\n",
      "GB           3.379440            22.783221\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "import mglearn\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'])\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "tree_score = cross_validate(tree, X_train, y_train, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "forest = RandomForestRegressor(max_depth = 5, random_state=0).fit(X_train, y_train)\n",
    "forest_score = cross_validate(forest, X_train, y_train, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 5, random_state=0).fit(X_train, y_train)\n",
    "gbrt_score = cross_validate(gbrt, X_train, y_train, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "results.loc['DT'] = [(np.average(tree_score['train_score']))*(-1), (np.average(tree_score['test_score']))*(-1)]\n",
    "\n",
    "results.loc['RF'] = [(np.average(forest_score['train_score']))*(-1), (np.average(forest_score['test_score']))*(-1)]\n",
    "\n",
    "results.loc['GB'] = [(np.average(gbrt_score['train_score']))*(-1), (np.average(gbrt_score['test_score']))*(-1)]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training Accuracy  Validation Accuracy\n",
      "DT           0.834465             0.738697\n",
      "RF           0.896557             0.840927\n",
      "GB           0.988171             0.919471\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "tree_score = cross_validate(tree, X_train, y_train, scoring='r2', return_train_score=True)\n",
    "forest_score = cross_validate(forest, X_train, y_train, scoring='r2', return_train_score=True)\n",
    "gbrt_score = cross_validate(gbrt, X_train, y_train, scoring='r2', return_train_score=True)\n",
    "\n",
    "results.loc['DT'] = [(np.average(tree_score['train_score'])), (np.average(tree_score['test_score']))]\n",
    "results.loc['RF'] = [(np.average(forest_score['train_score'])), (np.average(forest_score['test_score']))]\n",
    "results.loc['GB'] = [(np.average(gbrt_score['train_score'])), (np.average(gbrt_score['test_score']))]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. Overall the results ising these non-linear methods are better, the MSE values are lower (3-47 for training, and 22-73 for validation) versus the 111 for training and 95 for validation I got in assignment 2. The R2 values were also better (closer to 1) with values of 0.83-0.99 for training, and 0.74-0.92 for validation, compared to 0.61 for training and 0.62 for validation from assignment 2.\n",
    "2. For this dataset I would use the Gradient Boosting model as it has the lowest mean squared error, and the highest R2 value. A validation r2 score of 0.92 is quite good for a model.\n",
    "3. For the tree based models we could adjust the depth of the trees, and the number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from the class examples, and from the scikit-lean.org website.\n",
    "2. I completed all of the steps in numerical order.\n",
    "3. I did not use any AI tools for this process.\n",
    "4. No issues, just took some time to determine the proper syntax for the MSE and r2 calculations. The sklearn website was useful for that. Also had some confusion with the cross-validation as discussed in class, but was clarified with the D2L post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 2314\n",
      "X type <class 'pandas.core.frame.DataFrame'>\n",
      "y size: 178\n",
      "y type <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "  \n",
    "print(\"X size:\", X.size)\n",
    "print(\"X type\", type(X))\n",
    "print(\"y size:\", y.size)\n",
    "print(\"y type\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol                         0\n",
       "Malicacid                       0\n",
       "Ash                             0\n",
       "Alcalinity_of_ash               0\n",
       "Magnesium                       0\n",
       "Total_phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid_phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color_intensity                 0\n",
       "Hue                             0\n",
       "0D280_0D315_of_diluted_wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b37a6fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2        71\n",
       "1        59\n",
       "3        48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training Accuracy  Validation Accuracy\n",
      "DTC           0.994357             0.894017\n",
      "SVC           0.680427             0.676638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "import mglearn\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'])\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0).fit(X_train, y_train)\n",
    "tree_score = cross_validate(tree, X_train, y_train.values.ravel(), scoring='accuracy', return_train_score=True)\n",
    "\n",
    "svc = SVC(random_state=0).fit(X_train, y_train)\n",
    "svc_score = cross_validate(svc, X_train, y_train.values.ravel(), scoring='accuracy', return_train_score=True)\n",
    "\n",
    "results.loc['DTC'] = [(np.average(tree_score['train_score'])), (np.average(tree_score['test_score']))]\n",
    "results.loc['SVC'] = [(np.average(svc_score['train_score'])), (np.average(svc_score['test_score']))]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The method with the highest accuracy is the decision tree classifier'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "\"The method with the highest accuracy is the decision tree classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_val, \n",
    "                                        tree.predict(X_val), \n",
    "                                        cmap='coolwarm',\n",
    "                                        colorbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.85      0.81      0.83        21\n",
      "           3       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.78      0.79      0.78        45\n",
      "weighted avg       0.84      0.82      0.83        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, svc.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The training score and accuracy are both higher for the decision tree classifier (0.99, and 0.89 respectively). This is quite a bit better than the SVC scores of 0.68 and 0.68.\n",
    "1. The SVC was using the default C parameter of 1.0, so with more or less regularization the model might fit better. The data itself might also follow more regular pattern where a tree-based model is the best for predicting outcomes.\n",
    "1. Three (3) samples were incorrectly classified in step 3 with the tree-based model.\n",
    "1. In this case precision is more important as we want to correctly classify the wine, and keep the standards high. If there are false negatives it might affect the producer, but doesn't hurt the consumer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from the example notebooks for this class\n",
    "1. I completed the steps in numerical order.\n",
    "1. I did not use any AI for this assignment.\n",
    "1. I did not have any serious challenges, but I did need to review precision vs recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "Through the class and examples I've seen that real-life situations are often not linear and need to be modeled by more complex systems. The concrete example from assignment 2 and 3 shows that validation accuracy improves drastically going from a linear model to a gradient boosted model (0.62 to 0.92 r2 value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "I liked using the new non-linear models and seeing how they modeled more real-life scenarios.\n",
    "I find some of the data summary and analysis aspect challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Training Accuracy  Validation Accuracy\n",
      "Linear SVC           0.868295                  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\benre\\anaconda3\\envs\\ensf-ml\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'])\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC(max_iter=5000, random_state=0).fit(X_train, y_train)\n",
    "svc_score = cross_validate(linear_svm, X_train, y_train, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "results.loc['Linear SVC'] = [(np.average(svc_score['train_score'])), (np.average(svc_test_score['test_score']))]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "The linear SVM model is higher than the SVC model from above, but still not as accurate as the decision tree classifier. The linear SVM model is alright for this dataset, but I would not suggest using it as more accurate models exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
